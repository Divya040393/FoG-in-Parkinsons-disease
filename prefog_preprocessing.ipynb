{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "#from google.colab import drive\n",
    "#drive.mount(\"/content/gdrive\", force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\n",
    "                   os.getcwd(),\n",
    "                   'dataset'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Label the Data with 3rd class (Pre-FOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prefog(dataset,window_length = 4):\n",
    "  dataset.drop(index = list(dataset[dataset['Action'] == 0].index),inplace=True)\n",
    "  window_length = 64*window_length\n",
    "    \n",
    "  fog_index=[]\n",
    "  for i in dataset.index: \n",
    "      if dataset.loc[i,'Action'] == 2:\n",
    "        fog_index.append(i)\n",
    "  fog_index\n",
    "\n",
    "\n",
    "\n",
    "  start_indices=[]\n",
    "  for i in fog_index:\n",
    "    if (dataset.loc[i-1,'Action']!=dataset.loc[i,'Action']):\n",
    "      start_indices.append(i)\n",
    " \n",
    "\n",
    "  prefog=[]\n",
    "  for start in start_indices:\n",
    "    prefog_start = [x for x in range(start-window_length,start)]\n",
    "    prefog.append(prefog_start)\n",
    "\n",
    "  prefog = [item for sublist in prefog for item in sublist]\n",
    "\n",
    "  for i in prefog:\n",
    "       dataset.loc[i,'Action'] = 3\n",
    "  dataset['Action'] = dataset['Action'] - 1\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = []\n",
    "for person in os.listdir(data_path):\n",
    "    if '.txt' in person: \n",
    "        people.append(person)\n",
    "for window_length in range(1,5):\n",
    "    dataset = pd.DataFrame()\n",
    "    for person in people: \n",
    "        name = person.split('R')[0]\n",
    "        print (name)\n",
    "        file = data_path+\"\\\\\"+person\n",
    "        temp = pd.read_csv(file,delimiter= \" \", header = None)\n",
    "        print (person,' is read',end = '\\t')\n",
    "        if 2 in temp[max(temp.columns)].unique():\n",
    "            print ('Adding {} to dataset'.format(person),end = '\\t')\n",
    "            temp.columns = ['time','A_F','A_V','A_L','L_F','L_V','L_L','T_F','T_V','T_L','Action']    \n",
    "            temp = label_prefog(temp,window_length).reset_index(drop=True)\n",
    "            temp['name'] = name\n",
    "            print ('{} is labelled'.format(person))\n",
    "            dataset = pd.concat([dataset,temp],axis = 0)\n",
    "\n",
    "        print ('')\n",
    "    dataset.reset_index(drop =True,inplace=True) \n",
    "    to_path = data_path + \"\\\\raw_labelled\"\n",
    "    to_name = to_path +\"\\\\win_\"+str(window_length)+\".csv\"\n",
    "     \n",
    "    dataset.to_csv(to_name,index = False)\n",
    "\n",
    "\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Extract Non-Overlapping windows of length w *f_s from the continously logged accelerometer data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(act,window_length,dataframe):\n",
    "    \n",
    "  indices = list(dataframe[dataframe.Action == act].index)\n",
    "  groups = []\n",
    "  temp = []\n",
    "  group_count = 0\n",
    "  for i in range(len(indices)):\n",
    "    if i == len(indices)-1:\n",
    "      temp.append(indices[i])\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "      break\n",
    "    temp.append(indices[i])\n",
    "    if indices[i]+1 != indices[i+1]: \n",
    "      group_count+=1\n",
    "      groups.append(temp)\n",
    "      temp = []\n",
    "\n",
    "  fs = 64\n",
    "  window_length = 4\n",
    "  # window_length = window_length*fs\n",
    "\n",
    "  final_dataframe = pd.DataFrame()\n",
    "  for i in groups: \n",
    "    required = math.floor(len(i)/(window_length*fs))\n",
    "    \n",
    "    req_index = i[0:(required*fs)]\n",
    "    \n",
    "    final_dataframe = pd.concat([final_dataframe,dataframe.iloc[req_index,:]],axis = 0)\n",
    "  return final_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_length in range(1,5):\n",
    "  \n",
    "  path = os.getcwd()+\"/dataset\"\n",
    "  name = path+\"/raw_labelled/win_\"+str(window_length)+\".csv\"\n",
    "  dataframe = pd.read_csv(name)\n",
    "\n",
    "  activities = []\n",
    "  for act in range(3):\n",
    "    activities.append(create_window(act,window_length,dataframe))\n",
    "  to_write = pd.concat(activities,axis = 0)\n",
    "  to_path = path + \"/windows\"+\"/windowed_\"+str(window_length)+\".csv\"\n",
    "  to_write.to_csv(to_path,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file \n",
    "window_length = 4\n",
    "fs = 64\n",
    "# for window_length in range(1,5):\n",
    "w = window_length*fs\n",
    "FE_path = path + \"/windows/windowed_\"\n",
    "name = FE_path + str(window_length) + \".csv\"\n",
    "dataframe = pd.read_csv(name)\n",
    "\n",
    "df = dataframe.drop(columns=['time','Action','name'])\n",
    "stat = pd.DataFrame()\n",
    "\n",
    "\n",
    "col= list(df.columns)\n",
    "for s in col:    \n",
    "  print (s)\n",
    "  mn =[] \n",
    "  var = []\n",
    "  std = []\n",
    "  mav = []\n",
    "  rms =[]\n",
    "  for i in range(0,len(df),w):\n",
    "      mn_  = np.mean(df[s].iloc[i:i+w])\n",
    "      var_  = np.var(df[s].iloc[i:i+w])\n",
    "      std_  = np.std(df[s].iloc[i:i+w])\n",
    "      mav_  = np.mean(abs(df[s].iloc[i:i+w]))\n",
    "      rms_  = np.sqrt(np.mean((df[s].iloc[i:i+w])**2))\n",
    "\n",
    "      mn.append(mn_)\n",
    "      var.append(var_)\n",
    "      std.append(std_)\n",
    "      mav.append(mav_)\n",
    "      rms.append(rms_)\n",
    "\n",
    "  stat['mean_'+s] = mn\n",
    "  stat['var_'+s] = var\n",
    "  stat['std_'+s] = std\n",
    "  stat['rms_'+s] = rms\n",
    "  stat['mav_'+s] = mav\n",
    "\n",
    "\n",
    "stat.shape\n",
    "\n",
    "import copy\n",
    "stat1 = copy.copy(stat)\n",
    "stat1['w'] = dataframe['Action'].iloc[[x for x in range(0,len(dataframe),w)]].to_list()\n",
    "order = ['w']\n",
    "order += stat1.columns.to_list()[:-1]\n",
    "stat1 = stat1[order]\n",
    "stat1.columns\n",
    "col = stat1.columns.to_list()\n",
    "col[0] = 0\n",
    "stat1.columns = col\n",
    "feature_name = path + \"/features/time_\"+str(window_length)+\".csv\"\n",
    "stat1.to_csv(feature_name, index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "window_length = 1\n",
    "fs = 64\n",
    "# for window_length in range(1,5):\n",
    "w = window_length*fs\n",
    "FE_path = path + \"/windows/windowed_\"\n",
    "name = FE_path + str(window_length) + \".csv\"\n",
    "dataframe = pd.read_csv(name)\n",
    "\n",
    "df = dataframe.drop(columns=['time','Action','name'])\n",
    "\n",
    "col= list(df.columns)\n",
    "\n",
    "order=5\n",
    "\n",
    "fi=pd.DataFrame()\n",
    "\n",
    "power = pd.DataFrame()\n",
    "bands = {'locomotor' :(0.5,3),'freeze' :(3,8)}\n",
    "\n",
    "for s in col:\n",
    "    xtemp = []\n",
    "    xtemp1 = []\n",
    "    for i in range(0,len(df),w):\n",
    "        nyq=0.5*fs\n",
    "        \n",
    "        #locomotor band 0.5-3hz\n",
    "        loc_low= 0.5/nyq\n",
    "        loc_high=3/nyq\n",
    "        \n",
    "        #clipping off band from the window\n",
    "        b, a = butter(order, [loc_low, loc_high], btype='band')\n",
    "        y=lfilter(b,a,df[s].iloc[i:i+w])\n",
    "        \n",
    "        #total power in locomotor band\n",
    "        e1=sum([x**2 for x in y])\n",
    "\n",
    "        #freeze band 3-8hz\n",
    "        frez_low= 3/nyq\n",
    "        frez_high=8/nyq\n",
    "\n",
    "        #clipping off band from the window\n",
    "        b1, a1 = butter(order, [frez_low, frez_high], btype='band')\n",
    "        y1=lfilter(b1,a1,df[s].iloc[i:i+w])\n",
    "        #total power in locomotor band\n",
    "        e2=sum([x**2 for x in y1])\n",
    "        \n",
    "        FI=e2/e1\n",
    "        POW=e2+e1\n",
    "        xtemp.append(FI)\n",
    "        xtemp1.append(POW)\n",
    "    fi['FI'+s] = xtemp\n",
    "    power['P'+s] = xtemp1\n",
    "print (\"Freeze and power done\")\n",
    "\n",
    "w = window_length*fs\n",
    "E=[]\n",
    "for i in range(0,len(df),w):\n",
    "  energy = np.sum((df.iloc[i:i+w,:])**2)\n",
    "  E.append(energy)\n",
    "E = pd.DataFrame(E)\n",
    "E.columns = [\"EN_\" + x for x in df.columns]\n",
    "\n",
    "#Entropy \n",
    "from scipy.signal import periodogram\n",
    "\n",
    "peak_f = pd.DataFrame()\n",
    "PSE = pd.DataFrame()\n",
    "for s in col:\n",
    "  peakF = []\n",
    "  pse = []\n",
    "  for i in range(0,len(df),w):\n",
    "      f,Pxx_den = periodogram(df[s].iloc[i:i+w],fs)\n",
    "      p_norm = Pxx_den/sum(Pxx_den)\n",
    "      p_norm = list(filter(lambda a: a != 0, p_norm))\n",
    "      pse.append(-(np.sum(p_norm*np.log(p_norm))))\n",
    "      peak = (fs/w)*max(Pxx_den)\n",
    "      peakF.append(peak)\n",
    "  PSE['ENt_'+s] = pse\n",
    "  peak_f['peak_'+s] = peakF\n",
    "PSE.fillna(0,inplace = True)\n",
    "\n",
    "\n",
    "freq = pd.concat([fi,power,E,PSE,peak_f],axis = 1)\n",
    "\n",
    "feature_name = path + \"/features/freq_\"+str(window_length)+\".csv\"\n",
    "freq.to_csv(feature_name, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
